# About Me:
üî≠ I‚Äôm currently working on - A few projects - Tableau/ SQL/ AI agents
<br>üå± I‚Äôm currently learning - Web Development
<br>üí¨ Ask me about - Data Analysis, Statistics, Visualization, ML


## üåê Socials:
[![LinkedIn](https://img.shields.io/badge/LinkedIn-%230077B5.svg?logo=linkedin&logoColor=white)](https://www.linkedin.com/in/adityadabrase/) [![email](https://img.shields.io/badge/Email-D14836?logo=gmail&logoColor=white)](mailto:dabrase.a@gmail.com) 

# üíª Tech Stack:
![MySQL](https://img.shields.io/badge/mysql-4479A1.svg?style=for-the-badge&logo=mysql&logoColor=white) 
![MicrosoftSQLServer](https://img.shields.io/badge/Microsoft%20SQL%20Server-CC2927?style=for-the-badge&logo=microsoft%20sql%20server&logoColor=white) 
![Postgres](https://img.shields.io/badge/postgres-%23316192.svg?style=for-the-badge&logo=postgresql&logoColor=white) 
![SQLite](https://img.shields.io/badge/sqlite-%2307405e.svg?style=for-the-badge&logo=sqlite&logoColor=white) 
![Keras](https://img.shields.io/badge/Keras-%23D00000.svg?style=for-the-badge&logo=Keras&logoColor=white) 
![Matplotlib](https://img.shields.io/badge/Matplotlib-%23ffffff.svg?style=for-the-badge&logo=Matplotlib&logoColor=black) 
![mlflow](https://img.shields.io/badge/mlflow-%23d9ead3.svg?style=for-the-badge&logo=numpy&logoColor=blue) 
![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=for-the-badge&logo=numpy&logoColor=white) 
![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=for-the-badge&logo=pandas&logoColor=white) 
![Plotly](https://img.shields.io/badge/Plotly-%233F4F75.svg?style=for-the-badge&logo=plotly&logoColor=white) 
![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=for-the-badge&logo=PyTorch&logoColor=white) 
![scikit-learn](https://img.shields.io/badge/scikit--learn-%23F7931E.svg?style=for-the-badge&logo=scikit-learn&logoColor=white) 
![Scipy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=for-the-badge&logo=scipy&logoColor=%white) 
![TensorFlow](https://img.shields.io/badge/TensorFlow-%23FF6F00.svg?style=for-the-badge&logo=TensorFlow&logoColor=white) 

![PowerShell](https://img.shields.io/badge/PowerShell-%235391FE.svg?style=for-the-badge&logo=powershell&logoColor=white) 
![Python](https://img.shields.io/badge/python-3670A0?style=for-the-badge&logo=python&logoColor=ffdd54) 
![R](https://img.shields.io/badge/r-%23276DC3.svg?style=for-the-badge&logo=r&logoColor=white) 
![Windows Terminal](https://img.shields.io/badge/Windows%20Terminal-%234D4D4D.svg?style=for-the-badge&logo=windows-terminal&logoColor=white) 
![Azure](https://img.shields.io/badge/azure-%230072C6.svg?style=for-the-badge&logo=microsoftazure&logoColor=white) 
![Google Cloud](https://img.shields.io/badge/GoogleCloud-%234285F4.svg?style=for-the-badge&logo=google-cloud&logoColor=white) 
![AWS](https://img.shields.io/badge/AWS-%23FF9900.svg?style=for-the-badge&logo=amazon-aws&logoColor=white) 
![Apache Spark](https://img.shields.io/badge/Apache%20Spark-FDEE21?style=for-the-badge&logo=apachespark&logoColor=black) 
![Apache Hive](https://img.shields.io/badge/Apache%20Hive-FDEE21?style=for-the-badge&logo=apachehive&logoColor=black) 
![Apache Hadoop](https://img.shields.io/badge/Apache%20Hadoop-66CCFF?style=for-the-badge&logo=apachehadoop&logoColor=black) 
![Apache Kafka](https://img.shields.io/badge/Apache%20Kafka-000?style=for-the-badge&logo=apachekafka) 
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?style=for-the-badge&logo=Apache%20Airflow&logoColor=white) 
![Apache](https://img.shields.io/badge/apache-%23D42029.svg?style=for-the-badge&logo=apache&logoColor=white) 
![Git](https://img.shields.io/badge/git-%23F05033.svg?style=for-the-badge&logo=git&logoColor=white) 
![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)

![CSS3](https://img.shields.io/badge/css3-%231572B6.svg?style=for-the-badge&logo=css3&logoColor=white) 
![HTML5](https://img.shields.io/badge/html5-%23E34F26.svg?style=for-the-badge&logo=html5&logoColor=white) 
![Markdown](https://img.shields.io/badge/markdown-%23000000.svg?style=for-the-badge&logo=markdown&logoColor=white) 
![C](https://img.shields.io/badge/c-%2300599C.svg?style=for-the-badge&logo=c&logoColor=white) 
![Bootstrap](https://img.shields.io/badge/bootstrap-%238511FA.svg?style=for-the-badge&logo=bootstrap&logoColor=white) 
![Flask](https://img.shields.io/badge/flask-%23000.svg?style=for-the-badge&logo=flask&logoColor=white) 
![Flutter](https://img.shields.io/badge/Flutter-%2302569B.svg?style=for-the-badge&logo=Flutter&logoColor=white) 
![NPM](https://img.shields.io/badge/NPM-%23CB3837.svg?style=for-the-badge&logo=npm&logoColor=white) 
![OpenCV](https://img.shields.io/badge/opencv-%23white.svg?style=for-the-badge&logo=opencv&logoColor=white) 
![Snowflake](https://img.shields.io/badge/snowflake-%2329B5E8.svg?style=for-the-badge&logo=snowflake&logoColor=white) 
![SASS](https://img.shields.io/badge/SASS-hotpink.svg?style=for-the-badge&logo=SASS&logoColor=white) 
![Streamlit](https://img.shields.io/badge/Streamlit-%23FE4B4B.svg?style=for-the-badge&logo=streamlit&logoColor=white) 
![TailwindCSS](https://img.shields.io/badge/tailwindcss-%2338B2AC.svg?style=for-the-badge&logo=tailwind-css&logoColor=white) 


# üìä GitHub Stats:
![](https://github-readme-stats.vercel.app/api?username=adityadabrase&theme=dark&hide_border=false&include_all_commits=true&count_private=true)<br/>
![](https://nirzak-streak-stats.vercel.app/?user=adityadabrase&theme=dark&hide_border=false)<br/>
![](https://github-readme-stats.vercel.app/api/top-langs/?username=adityadabrase&theme=dark&hide_border=false&include_all_commits=true&count_private=true&layout=compact)

## üèÜ GitHub Trophies
![](https://github-profile-trophy.vercel.app/?username=adityadabrase&theme=radical&no-frame=false&no-bg=true&margin-w=4)

### ‚úçÔ∏è Random Dev Quote
![](https://quotes-github-readme.vercel.app/api?type=vetical&theme=dark)

---
[![](https://visitcount.itsvg.in/api?id=adityadabrase&icon=0&color=2)](https://visitcount.itsvg.in)

<!-- Proudly created with GPRM ( https://gprm.itsvg.in ) -->


<!--
# Portfolio Projects

## Project 1:  [Heath Insurance charge Prediction](https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/DS-ML/Insurance)
-  Description: Many factors influence health insurance premiums, and understanding these variables is crucial for predicting costs accurately. This project explores the relationships between age, gender, BMI, number of children, smoking habits, and region with health insurance charges.
- Skills used:  This project involves a diverse set of skills spanning data analysis, machine learning, data preprocessing, GitHub version control, Markdown documentation, statistical analysis, Jupyter Notebooks, Python programming, and regression modelling. The data analysis component includes exploratory data analysis (EDA) using Python libraries such as Pandas, NumPy, and Seaborn, visualizing data distributions, relationships, and summaries with Matplotlib and Seaborn, and interpreting statistical concepts like right-skewed distributions. Machine learning skills come into play with the implementation and evaluation of regression models, including Linear Regression, Ridge Regression, Lasso Regression, and Random Forest Regressor. Feature engineering, transformation, and selection, as well as handling categorical data using techniques like encoding, are part of the data preprocessing tasks. GitHub and version control facilitate collaborative development and code sharing. Documentation is created using Markdown, and the analysis is conducted in Jupyter Notebooks. The project also involves Python programming, specifically using libraries such as NumPy, Pandas, Matplotlib, Seaborn, and Scikit-Learn. The exploration of feature importance in machine learning models and the application of Polynomial Regression to capture non-linear relationships further enhance the depth and complexity of the project. Collectively, these skills contribute to a holistic approach in predicting health insurance charges based on various influencing factors.

  
## Project 2: [911 calls analysis using Python ](https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/DS-ML/911%20calls%20analysis)
- Description: Analyzing some 911 call data from Kaggle. (Exploratory data analysis and Data visualization)
- Skills used:  the skills required include proficient data cleaning and preprocessing abilities to handle emergency call data effectively. Exploratory Data Analysis (EDA) skills are crucial to understand patterns and trends in the data. Additionally, strong data visualization skills using libraries like Matplotlib and Seaborn are essential to present insights visually. If the analysis involves temporal data, skills in time series analysis become relevant. For projects dealing with geographic data, proficiency in geographic data analysis is necessary to make sense of location-based information.
  

## Project 3: [Customer Segmentation using K-Means Algorithm](https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/K%20means%20Algorithm)
-  Description:This project revolves around the application of the K-Means clustering algorithm to perform customer segmentation. Customer segmentation is a crucial task in marketing and business strategy, allowing companies to categorize customers based on similar attributes and behaviours. 
- Skills used:  Data Cleaning and Preprocessing, K-Means Clustering Algorithm, Exploratory Data Analysis (EDA), Data Visualization, Machine Learning with scikit-learn, Statistical Analysis
  
## Project 4: [Flight Delay Predictor](https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/DS-ML/FlightDelayPredictor)
-  Description: Models used: Linear Regression Decision Tree Random Forest Gradient Boosting SVM KNN.
- Skills used: machine learning skills are essential, particularly in classification tasks if predicting delays versus no delays. Time series analysis might be necessary if considering time-dependent factors in predicting flight delays. Feature engineering skills are crucial to extract relevant information from the dataset. Model evaluation and selection skills are needed to choose the best predictive model. Data cleaning and preprocessing skills are important to handle missing or noisy data effectively.

## Project 5: [Logistic Regression Project](https://github.com/AdityaDabrase/DSPortfolioProjects/blob/main/DS-ML/LR/Visualization-of-logistic-regression-model-of-an-exemplary-subject-Both-variables.png)
-  Description: Models used: Linear Regression Decision Tree Random Forest Gradient Boosting SVM KNN.
- Skills used: machine learning skills are employed, specifically logistic regression for binary classification tasks. Model evaluation and selection skills are crucial for assessing the performance of the logistic regression model. Feature engineering is important to identify and use relevant features for classification. Data cleaning and preprocessing skills are necessary for preparing the data for training the logistic regression model.

## Project 6: [Linear Regression Project](https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/DS-ML/Linear%20Regression%20Project)
-  Description: Models used: Linear Regression Decision Tree Random Forest Gradient Boosting SVM KNN.
- Skills used: skills involve linear regression for regression analysis. Model evaluation and selection skills are crucial for assessing the performance of the linear regression model. Feature engineering is important for identifying and utilizing relevant features in the regression analysis. Data cleaning and preprocessing skills are necessary for preparing the data for training the linear regression model.

## Project 7:  [Death Rate Prediction](https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/DS-ML/Death%20rate%20prediction)
-  Description: Models used: Linear Regression Decision Tree Random Forest Gradient Boosting SVM KNN.
- Skills used:  The project involves a machine learning approach to predict death rates. Skills required include regression analysis, feature engineering to enhance predictive features, and the ability to evaluate and select the most suitable model. Statistical analysis skills are beneficial for understanding the underlying patterns in the data. Furthermore, expertise in data cleaning and preprocessing is essential to prepare the data for model training.


https://github.com/AdityaDabrase/DSPortfolioProjects/tree/main/DS-ML/Insurance
<!--
**AdityaDabrase/AdityaDabrase** is a ‚ú® _special_ ‚ú® repository because its `README.md` (this file) appears on your GitHub profile.

Here are some ideas to get you started:

- üî≠ I‚Äôm currently working on ...
- üå± I‚Äôm currently learning ...
- üëØ I‚Äôm looking to collaborate on ...
- ü§î I‚Äôm looking for help with ...
- üí¨ Ask me about ...
- üì´ How to reach me: ...
- üòÑ Pronouns: ...
- üëØ I‚Äôm looking to collaborate on anything creative!
- ü§î I‚Äôm looking for help with iOS development
- ‚ö° Fun fact: ...


### My Portfolio
- **Data Visualization and Dashboarding**: ![Tableau](https://img.shields.io/badge/-Tableau-000?&logo=Tableau) ![Power BI](https://img.shields.io/badge/-PowerBI-000?&logo=PowerBI) ![Google Analytics](https://img.shields.io/badge/-GoogleAnalytics-000?&logo=GoogleAnalytics) 
  - [E-Commerce Sales Analysis | Minimal Overview Dashboard](https://public.tableau.com/views/E-CommerceSalesDashboard_16746667527820/Dashboard2?:language=en-GB&:display_count=n&:origin=viz_share_link) - <br> Built a dashboard using Tableau that analyzes credit card complaints data. The dashboard allows for a comprehensive analysis of the data through the use of custom calculations and parameters. This enables users to identify patterns and trends in the data, and make data-driven decisions. The visualizations in the dashboard are interactive and visually appealing, making it easy to understand and interpret the data. The purpose of the project is to improve customer satisfaction and reduce complaints by gaining a better understanding of the complaints data. <br/>
  - [Modern Retail Sales Dashboard | Aesthetic Light and Dark Themes](https://public.tableau.com/views/ModernRetailSalesDashboardRWFD/Main-Light?:language=en-GB&:display_count=n&:origin=viz_share_link) - <br> This Tableau dashboard presents a modern and aesthetic analysis of retail sales, with light and dark themes for user preference. Key performance indicators (KPIs) are displayed with current and previous year sparklines and min-max indicators, and users can customize the dashboard with global filters. An interactive text summary of sales by region allows for a quick and easy view of performance by location. <br/>
  - [A 100 Years of Earthquakes - Analysis of a century of Earthquakes | Story Book using Tableau](https://public.tableau.com/views/A100YearsofEarthquakeStoryboard/Dashboard1?:language=en-GB&:display_count=n&:origin=viz_share_link) - <br> This Tableau dashboard provides a comprehensive analysis of 100 years of earthquakes, presenting a visual representation of the data by year and magnitude, as well as a distribution of the earthquakes by class and magnitude. The dashboard also features an interactive earthquake map with filters for magnitude, damages, injuries, number of houses destroyed, number of missing, and number of deaths, allowing users to gain deeper insights into the impact of earthquakes over the past century. <br/>
  - [Bank and Credit Card Complaints Analysis using Tableau](https://public.tableau.com/views/BankandCreditCardComplaintsDashboard/Dashboard1?:language=en-GB&:display_count=n&:origin=viz_share_link) - <br> Built a dashboard using Tableau that analyzes credit card complaints data. The dashboard allows for a comprehensive analysis of the data through the use of custom calculations and parameters. This enables users to identify patterns and trends in the data, and make data-driven decisions. The visualizations in the dashboard are interactive and visually appealing, making it easy to understand and interpret the data. The purpose of the project is to improve customer satisfaction and reduce complaints by gaining a better understanding of the complaints data. <br/>
  - [Employee Attrition - What makes employees quit? | Futuristic Tableau and Power BI Dashboards](https://public.tableau.com/views/IBMAttritionAnalyticsDashboard/Dashboard1?:language=en-GB&:display_count=n&:origin=viz_share_link) - <br> This is an in-depth project that utilizes Tableau, Power BI, Python, Pig Latin, and Hadoop to gain a deeper understanding of IBM's workforce. The project meticulously investigates the Key Risk Indicators (KRIs) that influence employee attrition by leveraging the power of big data analysis. The project's results, in the form of recommendations, aim to aid IBM in enhancing employee retention and minimizing turnover rates. The project exemplifies the capability of advanced big data tools and visualization techniques to unveil actionable insights from large datasets. <br/>
  
- **Predictive Analytics and Machine Learning**:  ![Python](https://img.shields.io/badge/-Python-000?&logo=Python) ![TensorFlow](https://img.shields.io/badge/-TensorFlow-000?&logo=TensorFlow) ![PyTorch](https://img.shields.io/badge/-PyTorch-000?&logo=PyTorch) ![Pandas](https://img.shields.io/badge/-Pandas-000?&logo=Pandas) ![SAS](https://img.shields.io/badge/-SAS-000?&logo=SAS) ![SKLearn](https://img.shields.io/badge/-SKLearn-000?&logo=SKLearn) ![Keras](https://img.shields.io/badge/-Keras-000?&logo=Keras) ![R](https://img.shields.io/badge/-R-000?&logo=R)
  - [Artificial Neural Networks for Fraud Detection in Supply Chain Analytics: A Study on MLPClassifier and Keras](https://github.com/subhanjandas/Artificial-Neural-Networks-for-Fraud-Detection-in-Supply-Chain-Analytics-MLPClassifier-and-Keras) - <br>This study was aimed to detect fraudulent activities in the supply chain through the use of neural networks. The study focused on building two machine learning models using the MLPClassifier algorithm from the scikit-learn library and a custom neural network using the Keras library in Python. Both models were trained and tested on the DataCo Supply Chain dataset. The results showed that the custom neural network achieved an accuracy of 97.67% in detecting fraudulent transactions, demonstrating its potential to minimize financial losses for organizations.<br/>
  - [US Flight Delays Prediction Models based on Na√Øve Bayes, Regression Tree, and Logistic Regression Algorithms](https://github.com/subhanjandas/FlightDelays) - <br> This project uses Python and Scikit-learn library to predict flight delays in the United States using three machine learning algorithms (Naive Bayes, Regression Tree, and Logistic Regression). The data collected, preprocessed and divided into training and test sets to train and evaluate the prediction models. The Logistic Regression algorithm achieved the highest accuracy of 85.14% in predicting flight delays. The project serves as a valuable tool for airlines and airport management to improve flight schedules and reduce the number of flight delays for passengers.<br/>
  - [Predicting Housing Prices Using Multiple Linear Regression and k-NearestNeighbours (kNN)](https://github.com/subhanjandas/Predicting-Housing-Prices-Using-Multiple-Linear-Regression-and-k-NearestNeighbours-kNN) - <br> The objective of this project was to predict housing prices using two modeling techniques, multiple linear regression and k-Nearest Neighbours (kNN). The project aimed to construct accurate models to estimate real estate values by identifying relevant factors and their impact on the property's price. The multiple linear regression model was deemed to be the most suitable for prediction, with low Mean Absolute Error (MAE) and Root Mean Squared Error (RMSE). The kNN model with 10 nearest neighbors also performed well, with a low RMSE.<br/>
  - [Supermarket Organic Product Purchase Prediction - Data Mining and Modeling with SAS](https://github.com/subhanjandas/Supermarket-Organic-Product-Purchase-Prediction---Data-Mining-and-Modeling-with-SAS) - <br>
This project aimed to predict customer purchasing behavior for a supermarket's new line of organic products. Using data mining techniques, the customer loyalty program data was analyzed to identify factors affecting organic product purchases. The data was modeled using SAS Enterprise Miner to create accurate predictive models. The results of this study could assist the supermarket in understanding their customer base and effectively target marketing efforts.<br/>
  
- **DataBase Scripting, Querying and Analysis**: ![SQL](https://img.shields.io/badge/-SQL-000?&logo=MySQL) ![SQLite](https://img.shields.io/badge/-sqlite-000?&logo=sqlite) ![MariaDB](https://img.shields.io/badge/-mariadb-000?&logo=mariadb) ![Cassandra](https://img.shields.io/badge/-Cassandra-000?&logo=Cassandra) ![Neo4j](https://img.shields.io/badge/-Neo4j-000?&logo=Neo4j) ![NoSQL](https://img.shields.io/badge/-NoSQL-000?&logo=NoSQL) ![PostgreSQL](https://img.shields.io/badge/-Postgresql-000&?&logo=Postgresql)
  - [RDBMS to GraphDB - Big Data Analytics using Neo4j](https://github.com/subhanjandas/RDBMS-to-GraphDB---Big-Data-Analytics-using-Neo4j) - <br> This project involves migration from a traditional RDBMS to Neo4j for big data analytics. Using graph database technology, various business-critical questions are addressed, including identifying the employees who sold Tofu, the products sold with Tofu, the total number of products, top 5 products by sales, and the category with the highest sales. Neo4j's efficiency and effectiveness in managing big data provides valuable insights for decision making.<br/>
  - [Data Analysis for Digital Music Store using SQL](https://github.com/subhanjandas/Digital-Music-Store---Data-Analysis-using-SQL) - <br> This project is a data analysis of Chinook Digital Music Store using SQL queries and PostgreSQL database. The project aimed to identify and optimize business opportunities by analyzing customer and sales data, answering questions such as top-selling genres, top-selling artists, total value of sales by country. Data visualization techniques were used to present the results in an easy-to-understand format. <br/>
  
- **Big Data Analytics and Cloud**: ![Azure](https://img.shields.io/badge/-Azure-000?&logo=Azure&logoColor=F90) ![AWS](https://img.shields.io/badge/-AWS-000?&logo=Amazon-AWS&logoColor=F90) ![Docker](https://img.shields.io/badge/-Docker-000?&logo=Docker) ![Hadoop](https://img.shields.io/badge/-Hadoop-000?&logo=Hadoop&logoColor=F90) ![GCP](https://img.shields.io/badge/-Scala-000?&logo=Scala&logoColor=F90)
  - [Worldwide Sales Data Analysis and Exploration using Zeppelin, HDFS and Spark](https://github.com/subhanjandas/Worldwide-Sales-Data-Analysis-and-Exploration-using-Zeppelin-HDFS-and-Spark) - <br> This project aimed to analyze and understand worldwide sales data through the use of Zeppelin and HDFS. The primary objective was to utilize Spark's basic Scala commands and SQL to query and manipulate the data, providing valuable insights and findings for the customer.  <br/>
  - [User, Occupation and Movies, Ratings Data Exploration using Apache Hive](https://github.com/subhanjandas/User-Occupation-and-Movies-Ratings-Data-Exploration-using-Apache-Hive) - <br> In this project, the objective was to analyze the "User, Occupation, Movies, and Ratings" dataset using Apache Hive. The data was processed and analyzed using Hive's SQL-like query language and MapReduce framework, making it easier to handle large datasets. The focus of the analysis was to provide a comprehensive breakdown of the data and uncover key insights into user preferences and trends. <br/>
  
- **Advanced Excel, IBM SPSS Modler, IBM Cognos Analytics and Others**: ![Excel](https://img.shields.io/badge/-Excel-000?&logo=Excel&logoColor=F90) ![SPSS](https://img.shields.io/badge/-SPSS-000?&logo=SPSS) ![Cognos](https://img.shields.io/badge/-Cognos-000?&logo=Cognos)
  - [MoneyBall: Sports Predictive Analytics | Advance Excel and Data Analysis Toolpak](https://github.com/subhanjandas/MoneyBall-Sports-Predictive-Analytics-) - <br> This project used advanced Excel tools such as Solver and Data Analysis ToolPak to optimize a baseball team's lineup and maximize the expected return to risk ratio while adhering to a set salary budget. Data on over 500 players was collected, cleaned and analyzed to identify the best players and positions. Data visualization techniques were used to present the results in an easy-to-understand format. The project provided valuable insights into building a winning team within a budget constraint </br>
  - [IBM SPSS - A Comprehensive Guide to Data Analysis and Data Modeling](https://github.com/subhanjandas/IBM-SPSS---A-Comprehensive-Guide-to-Data-Analysis-and-Data-Modeling) - <br> IBM SPSS Modeler is a comprehensive data analysis and modeling tool. This repository is a compilation of exercises outlined in the "Introduction to IBM SPSS Modeler" document by IBM. It covers the essential steps of data import, preparation, visualization, and model building. The repository includes building decision trees and linear regression models, demonstrating the tool's modeling capabilities. </br>
  - [Telecomm Customer Churn - Data Modeling and Finding Main Drivers with IBM Cognos Analytics](https://github.com/subhanjandas/Data-Modelling-and-Dashboarding-with-IBM-Cognos-Analytics) - <br> In this project, IBM Cognos Analytics was used to analyze Telecomm customer churn data to determine the main drivers affecting customer churn. By answering questions such as what were the top three key drivers affecting churn, insights were gained on customer tenure with fiber optic, payment method, and internet service type. The results showed that customers with a tenure less than three months and fiber optic service, paying with electronic check, had the highest churn rate. </br>

-->